{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Single model data analysis",
   "id": "c19026448bc110cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from data import data\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ema_workbench.analysis import dimensional_stacking, feature_scoring\n",
    "\n",
    "from itertools import product"
   ],
   "id": "30f0cf31c29c017c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define parameter ranges\n",
    "av_cost_factors = [1.0, 0.5, 0.25]\n",
    "av_vot_factors = [1.0, 0.5, 0.25]\n",
    "av_densities = [1.5, 1.0, 0.5]\n",
    "induced_demands = [1.0, 1.25, 1.5]\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "param_combinations = list(product(av_cost_factors, av_vot_factors, av_densities, induced_demands))"
   ],
   "id": "949587efbf8106db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "area_names = data.mrdh65_to_name\n",
    "\n",
    "journeys_dict = {}\n",
    "uxsim_dict = {}\n",
    "parked_dict = {}\n",
    "\n",
    "# Runs are tuples with the 4 parameter values\n",
    "runs = param_combinations\n",
    "load_names = [f\"av_cost_{av_cost_factor}_av_vot_{av_vot_factor}_av_density_{av_density}_induced_{induced_demand}\" for av_cost_factor, av_vot_factor, av_density, induced_demand in param_combinations]\n",
    "variables = [\"av_cost\", \"av_vot\", \"av_density\", \"induced_demand\"]\n",
    "\n",
    "folder = \"exp2/\"\n",
    "for run, load_name in zip(runs, load_names):\n",
    "    try:\n",
    "        with open(f\"../results/{folder}uxsim_df_{load_name}.pkl\", \"rb\") as f:\n",
    "            uxsim_dict[run] = pickle.load(f)\n",
    "        with open(f\"../results/{folder}parked_dict_{load_name}.pkl\", \"rb\") as f:\n",
    "            parked_dict[run] = pickle.load(f)\n",
    "        journeys_dict[run] = pd.read_feather(f\"../results/{folder}journeys_df_{load_name}.feather\")\n",
    "    except:\n",
    "        pass\n",
    "print(f\"Loaded {len(journeys_dict)} of {len(param_combinations)} runs.\")"
   ],
   "id": "dd56f0db24627b63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "city_areas = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 28, 29, 31, 34, 41, 43, 44, 45]\n",
    "city_area_names = [area_names[area] for area in city_areas]\n",
    "\n",
    "trips_by_hour_chances = pd.read_pickle(\"../data/trips_by_hour_chances.pickle\")\n",
    "\n",
    "start_time, end_time = int(journeys_dict[runs[0]]['start_time'].min()), int(journeys_dict[runs[0]]['start_time'].max())\n",
    "print(f\"Start time: {start_time}, End time: {end_time}\")"
   ],
   "id": "323098a00b9ac278",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter the journeys\n",
    "for run, journeys_df in journeys_dict.items():\n",
    "    # Throw away the first 15 minutes. Road network is not fully loaded yet, so travel times are often 0.\n",
    "    journeys_dict[run] = journeys_df[journeys_df['start_time'] >= start_time + 0.25]\n",
    "    # Remove all journeys with that are not finished\n",
    "    journeys_dict[run] = journeys_dict[run][journeys_dict[run]['finished']]"
   ],
   "id": "426ee857e3293992",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Journeys data",
   "id": "e5a5161911b8117c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "journey_columns = ['agent', 'origin', 'destination', 'mode', 'start_time', 'travel_time', 'end_time', 'distance', 'cost', 'perceived_cost', 'comf_perceived_cost', 'used_network', 'started', 'finished', 'act_travel_time', 'act_perceived_cost', 'o_node', 'd_node', 'vehicle', 'car_available', 'av_available', 'perceived_cost_car', 'perceived_cost_bike', 'perceived_cost_transit', 'perceived_cost_av']",
   "id": "2ebeeb4baeb7994e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create journeys_agg_df with a multi-index of the parameters\n",
    "journeys_agg_df = pd.DataFrame(index=pd.MultiIndex.from_tuples(journeys_dict.keys(), names=variables))\n",
    "journeys_agg_df.index.set_names(variables, inplace=True)\n",
    "\n",
    "# Add the total number of journeys for each run\n",
    "journeys_agg_df['total_journeys'] = journeys_agg_df.index.map(lambda run: len(journeys_dict[run]))\n",
    "\n",
    "# Print the mode choice distribution\n",
    "mode_counts = {}\n",
    "mode_counts_weighted = {}\n",
    "\n",
    "for run, journeys_df in journeys_dict.items():\n",
    "    # Mode choice distribution\n",
    "    mode_counts[run] = journeys_df['mode'].value_counts(normalize=True).to_dict()\n",
    "\n",
    "    # Distance weighted mode choice distribution\n",
    "    mode_counts_weighted[run] = journeys_df.groupby('mode', observed=True)['distance'].sum() / journeys_df['distance'].sum()\n",
    "\n",
    "# Convert mode_counts and mode_counts_weighted to DataFrames\n",
    "modes_df = pd.concat([\n",
    "    pd.DataFrame.from_dict(mode_counts, orient='index').add_prefix('mode_share_'),\n",
    "    pd.DataFrame.from_dict(mode_counts_weighted, orient='index').add_prefix('mode_distance_share_')\n",
    "], axis=1)\n",
    "# Set index names to variables\n",
    "modes_df.index.set_names(variables, inplace=True)\n",
    "\n",
    "# Combine the two DataFrames\n",
    "journeys_agg_df = pd.concat([journeys_agg_df, modes_df], axis=1)\n",
    "journeys_agg_df"
   ],
   "id": "95259b9bacf3ae3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the total perceived costs per journey and add to the aggregated dataframe\n",
    "journeys_agg_df[\"mean_perceived_cost\"] = journeys_agg_df.index.map(lambda run: journeys_dict[run][\"perceived_cost\"].mean())\n",
    "journeys_agg_df[\"mean_comf_perceived_cost\"] = journeys_agg_df.index.map(lambda run: journeys_dict[run][\"comf_perceived_cost\"].mean())\n",
    "journeys_agg_df[\"mean_travel_time\"] = journeys_agg_df.index.map(lambda run: journeys_dict[run][\"travel_time\"].mean())\n",
    "journeys_agg_df[\"mean_speed\"] = journeys_agg_df.index.map(lambda run: journeys_dict[run][\"distance\"].sum() / (journeys_dict[run][\"travel_time\"].sum() / 3600))\n",
    "# mean network speed (used_network True)\n",
    "journeys_agg_df[\"mean_network_speed\"] = journeys_agg_df.index.map(lambda run: journeys_dict[run][journeys_dict[run][\"used_network\"]][\"distance\"].sum() / (journeys_dict[run][journeys_dict[run][\"used_network\"]][\"travel_time\"].sum() / 3600))\n",
    "journeys_agg_df[\"mean_car_speed\"] = journeys_agg_df.index.map(lambda run: journeys_dict[run][journeys_dict[run][\"mode\"] == \"car\"][\"distance\"].sum() / (journeys_dict[run][journeys_dict[run][\"mode\"] == \"car\"][\"travel_time\"].sum() / 3600))\n",
    "journeys_agg_df[\"mean_av_speed\"] = journeys_agg_df.index.map(lambda run: journeys_dict[run][journeys_dict[run][\"mode\"] == \"av\"][\"distance\"].sum() / (journeys_dict[run][journeys_dict[run][\"mode\"] == \"av\"][\"travel_time\"].sum() / 3600))\n",
    "journeys_agg_df"
   ],
   "id": "7157188918629c8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "comfort_factors = {\n",
    "    \"car\": 0.5,\n",
    "    \"bike\": 1.33,\n",
    "    \"transit\": 1,\n",
    "    \"av\": 0.5,\n",
    "}\n",
    "\n",
    "# Create a Series of comfort factors for easy mapping\n",
    "comfort_factors_series = pd.Series(comfort_factors)\n",
    "\n",
    "# Calculate saved costs for each journey\n",
    "for run, journeys_df in journeys_dict.items():\n",
    "    # Calculate the comfort-perceived cost for the chosen mode (vectorized)\n",
    "    journeys_df['actual_comf_perceived_cost'] = journeys_df['perceived_cost'] * journeys_df['mode'].map(comfort_factors_series)\n",
    "\n",
    "    # Calculate the comfort-perceived cost without AVs (vectorized)\n",
    "    comf_perceived_costs = journeys_df[['perceived_cost_car', 'perceived_cost_bike', 'perceived_cost_transit']].mul(\n",
    "        [comfort_factors['car'], comfort_factors['bike'], comfort_factors['transit']]\n",
    "    )\n",
    "    journeys_df['comf_perceived_cost_no_av'] = comf_perceived_costs.min(axis=1)\n",
    "\n",
    "    # Calculate saved costs, set to 0 if negative (vectorized)\n",
    "    journeys_df['saved_comf_perceived_cost'] = np.maximum(journeys_df['comf_perceived_cost_no_av'] - journeys_df['actual_comf_perceived_cost'], 0)\n",
    "\n",
    "    # Sum up the saved costs for each run\n",
    "    journeys_agg_df.loc[run, 'saved_comf_perceived_cost'] = journeys_df['saved_comf_perceived_cost'].sum()\n",
    "\n",
    "# Normalize the saved comfort perceived cost by the total number of journeys\n",
    "journeys_agg_df['saved_comf_perceived_cost_per_trip'] = journeys_agg_df['saved_comf_perceived_cost'] / journeys_agg_df['total_journeys']"
   ],
   "id": "9c039606fb8f9b50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display the updated DataFrame\n",
    "journeys_agg_df"
   ],
   "id": "37e4c90460d663ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Get reference data\n",
    "journey_ref_df = pd.read_feather(\"../results/journeys_df_base1_rush.feather\")\n",
    "journey_ref_df = journey_ref_df[journey_ref_df['start_time'] >= start_time + 0.25]\n",
    "journey_ref_df = journey_ref_df[journey_ref_df['finished']]\n",
    "\n",
    "### Calculate all the other metrics\n",
    "ref_values = {}\n",
    "# Mode choices\n",
    "ref_values.update(journey_ref_df['mode'].value_counts(normalize=True).add_prefix('mode_share_').to_dict())\n",
    "weighted = journey_ref_df.groupby('mode', observed=True)['distance'].sum() / journey_ref_df['distance'].sum()\n",
    "ref_values.update(weighted.add_prefix('mode_distance_share_').to_dict())\n",
    "ref_values['mode_share_av'] = 0\n",
    "ref_values['mode_distance_share_av'] = 0\n",
    "# Perceived costs\n",
    "ref_values['mean_perceived_cost'] = journey_ref_df['perceived_cost'].mean()\n",
    "ref_values['mean_comf_perceived_cost'] = journey_ref_df['comf_perceived_cost'].mean()\n",
    "ref_values['mean_travel_time'] = journey_ref_df['travel_time'].mean()\n",
    "ref_values['mean_speed'] = journey_ref_df['distance'].sum() / (journey_ref_df['travel_time'].sum() / 3600)\n",
    "ref_values['mean_network_speed'] = journey_ref_df[journey_ref_df['used_network']]['distance'].sum() / (journey_ref_df[journey_ref_df['used_network']]['travel_time'].sum() / 3600)\n",
    "ref_values['mean_car_speed'] = journey_ref_df[journey_ref_df['mode'] == 'car']['distance'].sum() / (journey_ref_df[journey_ref_df['mode'] == 'car']['travel_time'].sum() / 3600)\n",
    "ref_values['mean_av_speed'] = None\n",
    "# Saved comfort perceived cost\n",
    "ref_values['saved_comf_perceived_cost'] = 0\n",
    "ref_values['saved_comf_perceived_cost_per_trip'] = 0\n",
    "\n",
    "print(ref_values)"
   ],
   "id": "da3492a37237a2d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lower_is_better = ['mode_share_car', 'mode_distance_share_car', 'mean_perceived_cost', 'mean_comf_perceived_cost', 'mean_travel_time']\n",
    "neutral = ['mode_share_av', 'mode_share_transit', 'mode_distance_share_av', 'mode_distance_share_transit']\n",
    "higher_is_better = list(ref_values.keys() - set(lower_is_better) - set(neutral))\n",
    "print(f\"Lower is better: {lower_is_better}\\nNeutral: {neutral}\\nHigher is better: {higher_is_better}\")"
   ],
   "id": "6335f88dfcde03f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib\n",
    "\n",
    "# Assuming journeys_agg_df is already defined and contains the necessary data\n",
    "def create_heatmap(column='saved_comf_perceived_cost', colormap='RdYlGn', center=None, label_format=None, show=True, save=False):\n",
    "    name = column.replace('_', ' ')\n",
    "    # Reshape the data for the heatmap\n",
    "    heatmap_data = journeys_agg_df[column].unstack(['av_cost', 'av_vot'])\n",
    "\n",
    "    if label_format is None:\n",
    "        label_format = '.3g'  # Three significant digits\n",
    "    \n",
    "    # Create a larger figure for better visibility\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create the heatmap\n",
    "    # Set the center of the color map to 0 for diverging colormaps. No colorbar.\n",
    "    ax = sns.heatmap(heatmap_data, annot=True, fmt=label_format, cmap=colormap, center=center, square=True)\n",
    "\n",
    "    # Add a small black line on the color bar at the reference value, if any\n",
    "    if center is not None:\n",
    "        # Access the colorbar from the heatmap\n",
    "        cbar = ax.collections[0].colorbar\n",
    "        # Calculate the normalized position of the center value\n",
    "        norm = matplotlib.colors.Normalize(vmin=cbar.vmin, vmax=cbar.vmax)\n",
    "        y = norm(center)\n",
    "        # Get the colorbar's axis\n",
    "        cbar_ax = cbar.ax\n",
    "        # For vertical colorbars, add a horizontal line and place \"ref\" on the left\n",
    "        cbar_ax.axhline(y=y * (cbar_ax.get_ylim()[1] - cbar_ax.get_ylim()[0]) + cbar_ax.get_ylim()[0], color='black', linewidth=1)\n",
    "        cbar_ax.text(-0.3, y, f'ref\\n{center:{label_format}}', va='center', ha='center', color='black', fontsize=10, transform=cbar_ax.transAxes)\n",
    "\n",
    "    # Customize x-axis ticks\n",
    "    xlabels = ax.get_xticklabels()\n",
    "    # Only keep the outer label if it's the middle one\n",
    "    xlabels = ['\\n\\n'.join(reversed(label.get_text().split('-'))) if i % 3 == 1 else label.get_text().split('-')[1] for i, label in enumerate(xlabels)]\n",
    "    ax.set_xticklabels(xlabels, rotation=0)\n",
    "    ax.xaxis.set_tick_params(labelsize=8)\n",
    "    \n",
    "    # Customize y-axis ticks\n",
    "    ylabels = ax.get_yticklabels()\n",
    "    ylabels = [label.get_text().replace('-', '   ') if i % 3 == 1 else label.get_text().split('-')[1] for i, label in enumerate(ylabels)]\n",
    "    ax.set_yticklabels(ylabels, rotation=0)\n",
    "    ax.yaxis.set_tick_params(labelsize=8)\n",
    "    \n",
    "    # Add lines between the outer categories\n",
    "    for i in range(1, len(heatmap_data.columns.levels[0])):\n",
    "        ax.axvline(x=i * len(heatmap_data.columns.levels[1]), color='white', linewidth=1)\n",
    "    \n",
    "    for i in range(1, len(heatmap_data.index.levels[0])):\n",
    "        ax.axhline(y=i * len(heatmap_data.index.levels[1]), color='white', linewidth=1)\n",
    "    \n",
    "    # Set the title and labels\n",
    "    plt.title(f'Dimensionally-stacked heatmap of {name}', fontsize=16)\n",
    "    ax.set_xlabel('AV Value of Time\\nAV Cost')\n",
    "    ax.set_ylabel('AV Density\\nInduced Demand')\n",
    "    \n",
    "    # Adjust the layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(f'../img/exp2/heatmap_{column}.png', dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "column = 'mode_share_car'\n",
    "create_heatmap(column=column, colormap='RdYlGn', center=ref_values[column], label_format='.1%', show=True, save=False)"
   ],
   "id": "c2a0b421408fd57d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for column, ref in ref_values.items():\n",
    "    if column in lower_is_better:\n",
    "        colormap = 'RdYlGn_r'\n",
    "    if column in neutral:\n",
    "        colormap = 'BrBG'  # Blue-Yellow alternatives are: 'RdBu', 'coolwarm'\n",
    "    if column in higher_is_better:\n",
    "        colormap = 'RdYlGn'\n",
    "\n",
    "    if ref is not None and 0 < ref <= 1 or column in ['mode_share_av', 'mode_share_weighted_av']:\n",
    "        # Set format to percent\n",
    "        label_format = '.1%'\n",
    "    elif ref is not None and ref >= 300 or column in ['saved_comf_perceived_cost']:\n",
    "        # Set format to 0 decimal places\n",
    "        label_format = '.0f'\n",
    "    else:\n",
    "        label_format = None\n",
    "    \n",
    "    create_heatmap(column=column, colormap=colormap, center=ref, label_format=label_format, show=False, save=True)"
   ],
   "id": "4c584b2539f9ccc1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
