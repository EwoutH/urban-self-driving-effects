{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Single model data analysis",
   "id": "c19026448bc110cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from data import data\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "30f0cf31c29c017c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "area_names = data.mrdh65_to_name\n",
    "\n",
    "folder = \"\"\n",
    "image_folder = \"results\"\n",
    "image_name = \"base1\"\n",
    "load_names = [\"base1\"]\n",
    "runs = [\"base1\"]\n",
    "\n",
    "journeys_dict = {}\n",
    "uxsim_dict = {}\n",
    "parked_dict = {}\n",
    "\n",
    "for run, load_name in zip(runs, load_names):\n",
    "    with open(f\"../results/{folder}uxsim_df_{load_name}.pkl\", \"rb\") as f:\n",
    "        uxsim_dict[run] = pickle.load(f)\n",
    "    with open(f\"../results/{folder}parked_dict_{load_name}.pkl\", \"rb\") as f:\n",
    "        parked_dict[run] = pickle.load(f)\n",
    "    journeys_dict[run] = pd.read_feather(f\"../results/{folder}journeys_df_{load_name}.feather\")"
   ],
   "id": "dd56f0db24627b63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d1cf0f1102aadff4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "city_areas = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 28, 29, 31, 34, 41, 43, 44, 45]\n",
    "city_area_names = [area_names[area] for area in city_areas]\n",
    "\n",
    "trips_by_hour_chances = pd.read_pickle(\"../data/trips_by_hour_chances.pickle\")\n",
    "\n",
    "start_time, end_time = int(journeys_dict[runs[0]]['start_time'].min()), int(journeys_dict[runs[0]]['start_time'].max())\n",
    "end_time = 22\n",
    "print(f\"Start time: {start_time}, End time: {end_time}\")"
   ],
   "id": "323098a00b9ac278",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Throw away the first 15 minutes. Road network is not fully loaded yet, so travel times are often 0.\n",
    "for run, journeys_df in journeys_dict.items():\n",
    "    journeys_dict[run] = journeys_df[journeys_df['start_time'] > start_time + 0.25]"
   ],
   "id": "426ee857e3293992",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Journeys data",
   "id": "e5a5161911b8117c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print the mode choice distribution\n",
    "mode_counts = {}\n",
    "mode_counts_weighted = {}\n",
    "journey_counts = {}\n",
    "journey_counts_norm = {}\n",
    "\n",
    "for run, journeys_df in journeys_dict.items():\n",
    "    mode_counts[run] = journeys_df['mode'].value_counts(normalize=True).to_dict()\n",
    "    print(f\"{run} Mode choice distribution: {({mode: f\"{count:.2%}\" for mode, count in mode_counts[run].items()})}\")\n",
    "    \n",
    "    # Distance weighted mode choice distribution\n",
    "    mode_counts_weighted[run] = journeys_df.groupby('mode', observed=True)['distance'].sum() / journeys_df['distance'].sum()\n",
    "    print(f\"{run} Distance weighted mode choice distribution: {({mode: f\"{count:.2%}\" for mode, count in mode_counts_weighted[run].items()})}\")\n",
    "    \n",
    "    # start_time hour (float to int)\n",
    "    journeys_df['start_time_h'] = journeys_df['start_time'].astype(int)\n",
    "    \n",
    "    # Group by start_time\n",
    "    journeys_grouped = journeys_df.groupby(['start_time_h'])\n",
    "    journey_counts[run] = journeys_grouped['mode'].value_counts(normalize=False).unstack().fillna(0)\n",
    "    # Get the percentage for each mode of each hour in a dataframe\n",
    "    journey_counts_norm[run] = journeys_grouped['mode'].value_counts(normalize=True).unstack().fillna(0)\n",
    "    \n",
    "# Convert journey_counts and journey_counts_norm into multi-indexed DataFrames\n",
    "journey_counts_df = pd.concat(journey_counts, axis=0, keys=journey_counts.keys(), names=[\"Run\", \"Hour\"]).stack().reset_index()\n",
    "journey_counts_norm_df = pd.concat(journey_counts_norm, axis=0, keys=journey_counts_norm.keys(), names=[\"Run\", \"Hour\"]).stack().reset_index()\n",
    "\n",
    "# Plot with seaborn\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axs = axs.flatten()\n",
    "\n",
    "run_line_styles = [\"solid\", \"dashed\", \"dashdot\", \"dotted\"]\n",
    "run_line_styles = {run: style for run, style in zip(runs, run_line_styles)}\n",
    "\n",
    "for i, df in enumerate([journey_counts_df, journey_counts_norm_df]):\n",
    "    for run in runs:\n",
    "        dfr = df[df['Run'] == run]\n",
    "        style = run_line_styles[run]\n",
    "        sns.lineplot(data=dfr, x='Hour', y=0, hue='mode', linestyle=style, ax=axs[i])\n",
    "    axs[i].set_title(f\"Mode choice distribution over time ({'Absolute' if i == 0 else 'Normalized'})\")\n",
    "    axs[i].set_ylabel('Percentage')\n",
    "    axs[i].set_xlabel('Time of day (hour)')\n",
    "    axs[i].set_xlim(start_time, end_time)\n",
    "    axs[i].set_ylim(bottom=0)\n",
    "    if i == 1:\n",
    "        axs[i].get_legend().remove()\n",
    "\n",
    "# Custom legends\n",
    "run_legend_lines = [mlines.Line2D([], [], color='black', linestyle=run_line_styles[run], label=f'Run {run}') for run in runs]\n",
    "mode_colors = sns.color_palette()\n",
    "mode_legend_lines = [mlines.Line2D([], [], color=color, linestyle='-', label=mode) for color, mode in zip(mode_colors, df['mode'].unique())]\n",
    "custom_legend = run_legend_lines + mode_legend_lines\n",
    "axs[0].legend(handles=custom_legend, title='Legend', loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../img/{image_folder}/mode_distribution_{image_name}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "95259b9bacf3ae3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for run, journeys_df in journeys_dict.items():\n",
    "    # Local analysis. Select the 65x65 areas ['Noord', 'Kralingen', 'Rotterdam Centrum', 'Feyenoord', 'Delfshaven'] from journeys_df.mrdh65. Use the data.mrdh65_to_name dictionary to map the area numbers to names.\n",
    "    inner_rotterdam = ['Noord', 'Kralingen', 'Rotterdam Centrum', 'Feyenoord', 'Delfshaven']\n",
    "    # origin is in pc4, use data.pc4_to_mrdh65_city to map to mrdh65\n",
    "    journeys_df[\"origin_mrdh65_name\"] = journeys_df[\"origin\"].map(data.pc4_to_mrdh65_city).map(data.mrdh65_to_name)\n",
    "    journeys_df[\"destination_mrdh65_name\"] = journeys_df[\"destination\"].map(data.pc4_to_mrdh65_city).map(data.mrdh65_to_name)\n",
    "    \n",
    "    # Filter the area index over city_areas\n",
    "    journeys_df_rc = journeys_df[(journeys_df['origin_mrdh65_name'].isin(inner_rotterdam)) & (journeys_df['destination_mrdh65_name'].isin(inner_rotterdam))]\n",
    "    print(f\"Selected {len(journeys_df_rc)} journeys from the inner Rotterdam areas ({len(journeys_df_rc) / len(journeys_df):.2%}) of the total journeys.\")\n",
    "    \n",
    "    # Print the mode choice distribution\n",
    "    mode_counts = journeys_df_rc['mode'].value_counts(normalize=True).to_dict()\n",
    "    print(f\"Mode choice distribution: {({mode: f\"{count:.2%}\" for mode, count in mode_counts.items()})}\")\n",
    "    \n",
    "    # Distance weighted mode choice distribution\n",
    "    mode_counts_weighted = journeys_df_rc.groupby('mode', observed=True)['distance'].sum() / journeys_df_rc['distance'].sum()\n",
    "    print(f\"Distance weighted mode choice distribution: {({mode: f\"{count:.2%}\" for mode, count in mode_counts_weighted.items()})}\\n\")"
   ],
   "id": "c919b751bd720c10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "height = len(runs) * 4\n",
    "fig, axs = plt.subplots(len(runs), 4, figsize=(16, height))\n",
    "if len(runs) == 1:\n",
    "    axs = axs[np.newaxis, :]\n",
    "\n",
    "color_dict = {'bike': 'tab:blue', 'car': 'tab:orange', 'transit': 'tab:green', 'av': 'tab:red'}\n",
    "\n",
    "for j, (run, journeys_df) in enumerate(journeys_dict.items()):\n",
    "    journeys_df['travel_time_min'] = journeys_df['travel_time'] / 60\n",
    "    # Sort by mode, in this order: bike, car, transit, av\n",
    "    journeys_df = journeys_df.sort_values('mode', key=lambda x: x.map({'bike': 0, 'car': 1, 'transit': 2, 'av': 3}))\n",
    "    \n",
    "    n_bins = 40\n",
    "    hist_columns = ['travel_time_min', 'distance', 'cost', 'perceived_cost']\n",
    "    x_labels = ['Travel time (min)', 'Distance (km)', 'Cost (€)', 'Perceived cost (€)']\n",
    "    upper_xlim = [journeys_df[col].quantile(0.99) for col in hist_columns]\n",
    "    \n",
    "    # Histogram of each column\n",
    "    \n",
    "    for i, col in enumerate(hist_columns):\n",
    "        plot_df = journeys_df[(journeys_df[col] < upper_xlim[i]) & (journeys_df[col] > 0)][[col, 'mode']].copy()\n",
    "        sns.histplot(plot_df, x=col, hue='mode', multiple='stack', ax=axs[j, i], bins=n_bins, palette=color_dict)\n",
    "        if j == 0:\n",
    "            axs[j, i].set_title(f'{col} distribution')\n",
    "        axs[j, i].set_xlabel(x_labels[i])\n",
    "        axs[j, i].set_ylabel('Frequency')\n",
    "        axs[j, i].set_xlim(0, upper_xlim[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../img/{image_folder}/journeys_data_{image_name}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "c19e50559a461e0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Input data visualization (for comparison)",
   "id": "ca7d87b26731c7f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# In the base run, check if there are any travel times by car under 40 seconds\n",
    "journeys_base = journeys_dict[\"base\"]\n",
    "# Drop the first 15 minutes\n",
    "journeys_base = journeys_base[journeys_base['start_time'] > 5.15]\n",
    "# journeys_base_car = journeys_base[journeys_base['mode'] == 'car']\n",
    "journeys_base_car = journeys_base[journeys_base['travel_time'] < 60]\n",
    "journeys_base_car"
   ],
   "id": "fbe2f8f61f9d1fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For a weekday, take the average of days 0-3 (Monday-Thursday)\n",
    "trips_by_hour_chance = trips_by_hour_chances.iloc[:, 0:4].mean(axis=1).drop(\"Total\")\n",
    "# Drop the hours that are not in the range of the model and save as a dictionary\n",
    "trips_by_hour_chance = trips_by_hour_chance.loc[start_time:(end_time)]\n",
    "# Set column name\n",
    "trips_by_hour_chance.name = 'Chance'\n",
    "# To df\n",
    "trips_by_hour_chance = trips_by_hour_chance.reset_index()\n",
    "# Set hour as int\n",
    "trips_by_hour_chance['Hour'] = trips_by_hour_chance['Hour'].astype(int)\n",
    "trips_by_hour_chance.head(3)"
   ],
   "id": "8d3438a27ac62d9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot trips_by_hour_chances series\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "sns.barplot(data=trips_by_hour_chance, x='Hour', y='Chance', ax=ax)\n",
    "ax.set_title('Trip chances per Agent per hour')\n",
    "ax.set_ylabel('Chance of taking trip')\n",
    "ax.set_xlabel('Time of day (hour)')\n",
    "# Save\n",
    "plt.savefig(f'../img/input_data.png', dpi=300, bbox_inches='tight')"
   ],
   "id": "f49a1fa4b4863f46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### UXsim data analysis",
   "id": "29b3f4a502adf28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for run, uxsim_df in uxsim_dict.items():\n",
    "    # time_bin (first level multi index) from seconds to hours\n",
    "    uxsim_df.index = pd.MultiIndex.from_tuples([(time/3600+start_time, area) for time, area in uxsim_df.index], names=['time_bin', 'area'])\n",
    "    \n",
    "    # Filter the area index over city_areas\n",
    "    uxsim_df = uxsim_df.loc[(slice(None), city_areas), :]"
   ],
   "id": "65837f77b52c8644",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Plot\n",
    "# fig, axs = plt.subplots(3, 2, figsize=(12, 12))\n",
    "# axs = axs.flatten()\n",
    "# \n",
    "# plot_run = \"new_08\"\n",
    "# for i, variable in enumerate(uxsim_dict[plot_run].columns):\n",
    "#     sns.lineplot(data=uxsim_df, x='time_bin', y=variable,  ax=axs[i], errorbar=(\"pi\", 50), hue='area', palette='rocket')\n",
    "#     axs[i].set_title(f\"{variable} in different areas\")\n",
    "#     axs[i].set_ylabel(variable)\n",
    "#     axs[i].set_xlabel('Time of day (hour)')\n",
    "#     axs[i].set_xlim(start_time, end_time)\n",
    "#     axs[i].set_ylim(bottom=0)\n",
    "#     \n",
    "# plt.savefig(f'../img/{image_folder}/uxsim_data_{image_name}_{plot_run}.png', dpi=300, bbox_inches='tight')"
   ],
   "id": "b85622ab36a98735",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merge into one df\n",
    "long_uxsim_df = pd.concat(uxsim_dict, axis=0, keys=uxsim_dict.keys(), names=[\"Run\"]).stack().reset_index()\n",
    "long_uxsim_df.columns = ['Run', 'time_bin', 'area', 'variable', 'value']\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(3, 2, figsize=(14, 14))\n",
    "axs = axs.flatten()\n",
    "errorbar = (\"pi\", 50)\n",
    "\n",
    "for i, variable in enumerate(uxsim_dict[runs[0]].columns):\n",
    "    sns.lineplot(data=long_uxsim_df[long_uxsim_df['variable'] == variable], x='time_bin', y='value',  ax=axs[i], errorbar=errorbar, hue='Run')\n",
    "    axs[i].set_title(f\"{variable} in different areas\")\n",
    "    axs[i].set_ylabel(variable)\n",
    "    axs[i].set_xlabel('Time of day (hour)')\n",
    "    axs[i].set_xlim(start_time, end_time)\n",
    "    axs[i].set_ylim(bottom=0)\n",
    "# Add a legend\n",
    "labels = [[f'Run {run}', f\"{errorbar[1]}% {errorbar[0]}\"] for run in runs]\n",
    "flat_labels = [item for sublist in labels for item in sublist]\n",
    "fig.legend(title='Run', loc=(0.9, 0.5), labels=flat_labels)\n",
    "\n",
    "plt.savefig(f'../img/{image_folder}/uxsim_data_{image_name}.png', dpi=300, bbox_inches='tight')"
   ],
   "id": "ecd61ff7ffd55c29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "long_uxsim_df_city = long_uxsim_df[long_uxsim_df['area'].isin(city_areas)]\n",
    "\n",
    "min_vars = ['average_speed']\n",
    "max_vars = ['average_delay', 'total_travel_time', 'traffic_volume', 'vehicle_density', 'vehicles_remain']\n",
    "\n",
    "# For variables in min_vars, apply the 'min' function\n",
    "min_df = long_uxsim_df_city[long_uxsim_df_city['variable'].isin(min_vars)].copy()\n",
    "\n",
    "# For variables in max_vars, apply the 'max' function\n",
    "max_df = long_uxsim_df_city[long_uxsim_df_city['variable'].isin(max_vars)].copy()\n",
    "\n",
    "min_aggregated = min_df.groupby(['Run', 'area', 'variable'], as_index=False)['value'].min()\n",
    "min_aggregated.rename(columns={'value': 'aggregated_value'}, inplace=True)\n",
    "\n",
    "max_aggregated = max_df.groupby(['Run', 'area', 'variable'], as_index=False)['value'].max()\n",
    "max_aggregated.rename(columns={'value': 'aggregated_value'}, inplace=True)\n",
    "\n",
    "aggregated_df = pd.concat([min_aggregated, max_aggregated], ignore_index=True)\n",
    "aggregated_df['aggregated_value'] = aggregated_df['aggregated_value'].fillna(0)"
   ],
   "id": "d7170ad983959ad8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create heatmaps\n",
    "fig, axs = plt.subplots(6, 1, figsize=(10, 12))\n",
    "axs = axs.flatten()\n",
    "vars = min_vars + max_vars\n",
    "plt.tight_layout()\n",
    "\n",
    "for i, variable in enumerate(vars):\n",
    "    agg_method = 'min' if variable in min_vars else 'max'\n",
    "    # Filter the DataFrame for the current variable\n",
    "    df_filtered = aggregated_df[aggregated_df['variable'] == variable]\n",
    "\n",
    "    # Pivot the DataFrame to get 'Run' as rows and 'area' as columns\n",
    "    heatmap_data = df_filtered.pivot(index='Run', columns='area', values='aggregated_value')\n",
    "\n",
    "    # Plot the heatmap using seaborn. Red-green color map is used. If max, reverse the color map.\n",
    "    color_map = 'RdYlGn_r' if agg_method == 'max' else 'RdYlGn'\n",
    "    sns.heatmap(heatmap_data, ax=axs[i], cmap=color_map, cbar_kws={'label': variable}, vmin=0, square=True)\n",
    "\n",
    "    # Set title for each heatmap\n",
    "    axs[i].set_title(f'{variable} ({agg_method})')\n",
    "    \n",
    "    # For the last subplot, use full area names with numbers as x-tick labels\n",
    "    if i == len(vars) - 1:\n",
    "        full_area_labels = [f'{area_names[area]} ({area})' for area in city_areas]\n",
    "        axs[i].set_xticklabels(full_area_labels, rotation=60, ha='right')\n",
    "\n",
    "# Save the figure\n",
    "plt.suptitle('Heatmaps for min and max values of different variables in different areas')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../img/{image_folder}/uxsim_heatmaps_{image_name}.png', dpi=300, bbox_inches='tight')"
   ],
   "id": "9e428defad3036f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Parking data visualization",
   "id": "3ba0d41efd49a2d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert parked_dict to DataFrame\n",
    "parked_df = pd.DataFrame(parked_dict)\n",
    "# Long form\n",
    "long_parked_df = parked_df.stack().reset_index()\n",
    "# Rename columns\n",
    "long_parked_df.columns = ['area', 'time', 'value']\n",
    "long_parked_df = long_parked_df.set_index(['time', 'area'])\n",
    "\n",
    "# Normalize the values on the first time step\n",
    "long_parked_df['parked_norm'] = long_parked_df.groupby('area')['value'].transform(lambda x: x / x.iloc[0])\n",
    "long_parked_df.head(3)"
   ],
   "id": "8f2c404ae6d83c24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gdf_mrdh_65 = pd.read_pickle(\"../data/areas_mrdh_weighted_centroids.pkl\")",
   "id": "de8775c069dd65af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(\"../data/polygons.pkl\", \"rb\") as f:\n",
    "    city_polygon, area_polygon = pickle.load(f)\n",
    "\n",
    "city_polygon_series = gpd.GeoSeries(city_polygon, crs=\"epsg:4326\")\n",
    "city_polygon_series = city_polygon_series.to_crs(epsg=28992)\n",
    "gdf_mrdh_65[\"in_city\"] = gdf_mrdh_65.centroid.within(city_polygon_series.geometry[0])\n",
    "gdf_mrdh_65 = gdf_mrdh_65[gdf_mrdh_65[\"in_city\"]]"
   ],
   "id": "3dca6d09056b6a8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a dictionary mapping the index to the area of gdf_mrdh_65\n",
    "area_dict = (gdf_mrdh_65.area / 1000000).to_dict()\n",
    "\n",
    "# Calculate the parked cars per area\n",
    "long_parked_df[\"parked_density\"] = long_parked_df[\"value\"] / long_parked_df.index.get_level_values(\"area\").map(area_dict)\n",
    "long_parked_df.head(3)"
   ],
   "id": "6b8008f998d11e1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n",
    "axs = axs.flatten()\n",
    "for i, col in enumerate(['value', 'parked_norm', 'parked_density']):\n",
    "    sns.lineplot(data=long_parked_df, x='time', y=col, hue='area', palette='rocket', ax=axs[i])\n",
    "    axs[i].set_title(f'Parked cars in different areas ({col})')\n",
    "    axs[i].set_ylabel('Parked cars')\n",
    "    axs[i].set_xlabel('Time of day (hour)')\n",
    "    axs[i].set_xlim(start_time, end_time)\n",
    "    if col == 'value':\n",
    "        axs[i].set_ylim(bottom=0)\n",
    "\n",
    "# Save image\n",
    "plt.savefig(f'../img/{image_folder}/parked_data_{image_name}.png', dpi=300, bbox_inches='tight')"
   ],
   "id": "d33f72bcd06c3e28",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
